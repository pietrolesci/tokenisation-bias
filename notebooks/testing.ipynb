{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/home/pl487/rdd/data/slim-pajama-subset-validation-sample-bpe32000/contexts\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/home/pl487/rdd/outputs/model_train/pythia-9M-bpe32000/checkpoints/checkpoint-50000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(ds[0][\"input_ids\"], dtype=torch.long)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.forward(input_ids=t).logits\n",
    "logprobs = logits.log_softmax(-1)\n",
    "labels = t.clone()\n",
    "\n",
    "shift_logits = logits[..., :-1, :].contiguous()\n",
    "shift_logprobs = logprobs[..., :-1, :].contiguous()\n",
    "shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "# Get the log-probability of the true token\n",
    "# (batch, seq, vocab = 1), there is an extra dim that makes it broadcastable to `shift_logprobs`\n",
    "true_logprobs = shift_logprobs.take_along_dim(dim=-1, indices=shift_labels[..., None])\n",
    "sup = true_logprobs.squeeze(-1).neg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2836, 2.3509, 7.0118,  ..., 0.0324, 2.0413, 3.3009]],\n",
       "       grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048, 32000])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = torch.nn.functional.cross_entropy(shift_logits.permute(0, 2, 1), shift_labels, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2836, 2.3508, 7.0118,  ..., 0.0323, 2.0413, 3.3008]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.pad([1, 2, 3], (2, 0), constant_values=0), np.pad([1, 2, 3], (2, 0), constant_values=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pl.read_parquet(\"/home/pl487/rdd/outputs/model_eval/2024-09-11T11-06-11/pythia-9M-bpe32000.parquet\")\n",
    "b = pl.read_parquet(\"/home/pl487/rdd/outputs/model_eval/2024-09-11T11-31-36/pythia-9M-bpe32000.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (149_434, 9)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>sup</th><th>rank</th><th>entropy</th><th>uid</th><th>new_token_id</th><th>input_ids</th><th>sup_right</th><th>rank_right</th><th>entropy_right</th></tr><tr><td>list[f64]</td><td>list[i64]</td><td>list[f64]</td><td>i64</td><td>i64</td><td>list[i64]</td><td>list[f64]</td><td>list[i64]</td><td>list[f64]</td></tr></thead><tbody><tr><td>[1.383524, 3.333795]</td><td>[0, 3]</td><td>[4.181461, 5.62039]</td><td>84</td><td>31567</td><td>[540, 31567]</td><td>[2.059909, 3.300911]</td><td>[1, 2]</td><td>[4.185226, 4.343543]</td></tr><tr><td>[1.213583, 10.371901]</td><td>[0, 2604]</td><td>[4.736505, 7.015377]</td><td>84</td><td>31881</td><td>[262, 31881]</td><td>[1.272575, 8.572933]</td><td>[0, 738]</td><td>[5.03889, 6.998665]</td></tr><tr><td>[5.590575, 9.243664]</td><td>[33, 1059]</td><td>[4.292186, 6.798021]</td><td>127</td><td>31655</td><td>[1817, 31655]</td><td>[4.976245, 10.881699]</td><td>[15, 1325]</td><td>[3.17473, 3.348009]</td></tr><tr><td>[4.397538, 9.070292]</td><td>[6, 569]</td><td>[1.681468, 3.974308]</td><td>157</td><td>31569</td><td>[281, 31569]</td><td>[4.597424, 4.831842]</td><td>[5, 8]</td><td>[1.517665, 4.55687]</td></tr><tr><td>[1.967112, 6.330029]</td><td>[0, 68]</td><td>[4.861785, 5.456806]</td><td>157</td><td>31238</td><td>[432, 31238]</td><td>[2.048149, 8.504574]</td><td>[0, 338]</td><td>[5.06059, 5.027475]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>[1.740024, 6.415906]</td><td>[2, 92]</td><td>[1.653188, 6.302306]</td><td>103405</td><td>31932</td><td>[364, 31932]</td><td>[1.693829, 6.449864]</td><td>[2, 94]</td><td>[1.680988, 6.278137]</td></tr><tr><td>[4.799245, 13.960602]</td><td>[10, 11265]</td><td>[4.09253, 4.861162]</td><td>107976</td><td>31671</td><td>[1237, 31671]</td><td>[4.900066, 14.020318]</td><td>[11, 11435]</td><td>[4.061255, 4.795384]</td></tr><tr><td>[6.604518, 13.779301]</td><td>[73, 10834]</td><td>[5.865509, 4.507862]</td><td>108539</td><td>31070</td><td>[5616, 31070]</td><td>[6.594501, 13.775612]</td><td>[72, 10883]</td><td>[5.804174, 4.513897]</td></tr><tr><td>[3.648093, 12.668388]</td><td>[1, 6216]</td><td>[7.356655, 6.21884]</td><td>113782</td><td>31658</td><td>[13, 31658]</td><td>[3.665712, 12.639827]</td><td>[1, 6194]</td><td>[7.360681, 6.237061]</td></tr><tr><td>[3.173638, 10.924004]</td><td>[1, 4780]</td><td>[5.456281, 6.909968]</td><td>140870</td><td>31438</td><td>[2371, 31438]</td><td>[3.202414, 10.921802]</td><td>[1, 4757]</td><td>[5.48964, 6.887547]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (149_434, 9)\n",
       "┌────────────┬────────────┬───────────┬────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ sup        ┆ rank       ┆ entropy   ┆ uid    ┆ … ┆ input_ids ┆ sup_right ┆ rank_righ ┆ entropy_r │\n",
       "│ ---        ┆ ---        ┆ ---       ┆ ---    ┆   ┆ ---       ┆ ---       ┆ t         ┆ ight      │\n",
       "│ list[f64]  ┆ list[i64]  ┆ list[f64] ┆ i64    ┆   ┆ list[i64] ┆ list[f64] ┆ ---       ┆ ---       │\n",
       "│            ┆            ┆           ┆        ┆   ┆           ┆           ┆ list[i64] ┆ list[f64] │\n",
       "╞════════════╪════════════╪═══════════╪════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ [1.383524, ┆ [0, 3]     ┆ [4.181461 ┆ 84     ┆ … ┆ [540,     ┆ [2.059909 ┆ [1, 2]    ┆ [4.185226 │\n",
       "│ 3.333795]  ┆            ┆ ,         ┆        ┆   ┆ 31567]    ┆ ,         ┆           ┆ ,         │\n",
       "│            ┆            ┆ 5.62039]  ┆        ┆   ┆           ┆ 3.300911] ┆           ┆ 4.343543] │\n",
       "│ [1.213583, ┆ [0, 2604]  ┆ [4.736505 ┆ 84     ┆ … ┆ [262,     ┆ [1.272575 ┆ [0, 738]  ┆ [5.03889, │\n",
       "│ 10.371901] ┆            ┆ ,         ┆        ┆   ┆ 31881]    ┆ ,         ┆           ┆ 6.998665] │\n",
       "│            ┆            ┆ 7.015377] ┆        ┆   ┆           ┆ 8.572933] ┆           ┆           │\n",
       "│ [5.590575, ┆ [33, 1059] ┆ [4.292186 ┆ 127    ┆ … ┆ [1817,    ┆ [4.976245 ┆ [15,      ┆ [3.17473, │\n",
       "│ 9.243664]  ┆            ┆ ,         ┆        ┆   ┆ 31655]    ┆ , 10.8816 ┆ 1325]     ┆ 3.348009] │\n",
       "│            ┆            ┆ 6.798021] ┆        ┆   ┆           ┆ 99]       ┆           ┆           │\n",
       "│ [4.397538, ┆ [6, 569]   ┆ [1.681468 ┆ 157    ┆ … ┆ [281,     ┆ [4.597424 ┆ [5, 8]    ┆ [1.517665 │\n",
       "│ 9.070292]  ┆            ┆ ,         ┆        ┆   ┆ 31569]    ┆ ,         ┆           ┆ ,         │\n",
       "│            ┆            ┆ 3.974308] ┆        ┆   ┆           ┆ 4.831842] ┆           ┆ 4.55687]  │\n",
       "│ [1.967112, ┆ [0, 68]    ┆ [4.861785 ┆ 157    ┆ … ┆ [432,     ┆ [2.048149 ┆ [0, 338]  ┆ [5.06059, │\n",
       "│ 6.330029]  ┆            ┆ ,         ┆        ┆   ┆ 31238]    ┆ ,         ┆           ┆ 5.027475] │\n",
       "│            ┆            ┆ 5.456806] ┆        ┆   ┆           ┆ 8.504574] ┆           ┆           │\n",
       "│ …          ┆ …          ┆ …         ┆ …      ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ [1.740024, ┆ [2, 92]    ┆ [1.653188 ┆ 103405 ┆ … ┆ [364,     ┆ [1.693829 ┆ [2, 94]   ┆ [1.680988 │\n",
       "│ 6.415906]  ┆            ┆ ,         ┆        ┆   ┆ 31932]    ┆ ,         ┆           ┆ ,         │\n",
       "│            ┆            ┆ 6.302306] ┆        ┆   ┆           ┆ 6.449864] ┆           ┆ 6.278137] │\n",
       "│ [4.799245, ┆ [10,       ┆ [4.09253, ┆ 107976 ┆ … ┆ [1237,    ┆ [4.900066 ┆ [11,      ┆ [4.061255 │\n",
       "│ 13.960602] ┆ 11265]     ┆ 4.861162] ┆        ┆   ┆ 31671]    ┆ , 14.0203 ┆ 11435]    ┆ ,         │\n",
       "│            ┆            ┆           ┆        ┆   ┆           ┆ 18]       ┆           ┆ 4.795384] │\n",
       "│ [6.604518, ┆ [73,       ┆ [5.865509 ┆ 108539 ┆ … ┆ [5616,    ┆ [6.594501 ┆ [72,      ┆ [5.804174 │\n",
       "│ 13.779301] ┆ 10834]     ┆ ,         ┆        ┆   ┆ 31070]    ┆ , 13.7756 ┆ 10883]    ┆ ,         │\n",
       "│            ┆            ┆ 4.507862] ┆        ┆   ┆           ┆ 12]       ┆           ┆ 4.513897] │\n",
       "│ [3.648093, ┆ [1, 6216]  ┆ [7.356655 ┆ 113782 ┆ … ┆ [13,      ┆ [3.665712 ┆ [1, 6194] ┆ [7.360681 │\n",
       "│ 12.668388] ┆            ┆ ,         ┆        ┆   ┆ 31658]    ┆ , 12.6398 ┆           ┆ ,         │\n",
       "│            ┆            ┆ 6.21884]  ┆        ┆   ┆           ┆ 27]       ┆           ┆ 6.237061] │\n",
       "│ [3.173638, ┆ [1, 4780]  ┆ [5.456281 ┆ 140870 ┆ … ┆ [2371,    ┆ [3.202414 ┆ [1, 4757] ┆ [5.48964, │\n",
       "│ 10.924004] ┆            ┆ ,         ┆        ┆   ┆ 31438]    ┆ , 10.9218 ┆           ┆ 6.887547] │\n",
       "│            ┆            ┆ 6.909968] ┆        ┆   ┆           ┆ 02]       ┆           ┆           │\n",
       "└────────────┴────────────┴───────────┴────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.join(b, on=[\"uid\", \"new_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (99_200, 6)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_token_id</th><th>uid</th><th>input_ids</th><th>sup</th><th>rank</th><th>entropy</th></tr><tr><td>i64</td><td>i64</td><td>list[i64]</td><td>list[f64]</td><td>list[i64]</td><td>list[f64]</td></tr></thead><tbody><tr><td>31567</td><td>84</td><td>[540, 31567]</td><td>[2.059909, 3.300911]</td><td>[1, 2]</td><td>[4.185226, 4.343543]</td></tr><tr><td>31881</td><td>84</td><td>[262, 31881]</td><td>[1.272575, 8.572933]</td><td>[0, 738]</td><td>[5.03889, 6.998665]</td></tr><tr><td>31655</td><td>127</td><td>[1817, 31655]</td><td>[4.976245, 10.881699]</td><td>[15, 1325]</td><td>[3.17473, 3.348009]</td></tr><tr><td>31569</td><td>157</td><td>[281, 31569]</td><td>[4.597424, 4.831842]</td><td>[5, 8]</td><td>[1.517665, 4.55687]</td></tr><tr><td>31238</td><td>157</td><td>[432, 31238]</td><td>[2.048149, 8.504574]</td><td>[0, 338]</td><td>[5.06059, 5.027475]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>31932</td><td>103405</td><td>[364, 31932]</td><td>[1.693829, 6.449864]</td><td>[2, 94]</td><td>[1.680988, 6.278137]</td></tr><tr><td>31671</td><td>107976</td><td>[1237, 31671]</td><td>[4.900066, 14.020318]</td><td>[11, 11435]</td><td>[4.061255, 4.795384]</td></tr><tr><td>31070</td><td>108539</td><td>[5616, 31070]</td><td>[6.594501, 13.775612]</td><td>[72, 10883]</td><td>[5.804174, 4.513897]</td></tr><tr><td>31658</td><td>113782</td><td>[13, 31658]</td><td>[3.665712, 12.639827]</td><td>[1, 6194]</td><td>[7.360681, 6.237061]</td></tr><tr><td>31438</td><td>140870</td><td>[2371, 31438]</td><td>[3.202414, 10.921802]</td><td>[1, 4757]</td><td>[5.48964, 6.887547]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (99_200, 6)\n",
       "┌──────────────┬────────┬───────────────┬────────────┬─────────────┬──────────────────────┐\n",
       "│ new_token_id ┆ uid    ┆ input_ids     ┆ sup        ┆ rank        ┆ entropy              │\n",
       "│ ---          ┆ ---    ┆ ---           ┆ ---        ┆ ---         ┆ ---                  │\n",
       "│ i64          ┆ i64    ┆ list[i64]     ┆ list[f64]  ┆ list[i64]   ┆ list[f64]            │\n",
       "╞══════════════╪════════╪═══════════════╪════════════╪═════════════╪══════════════════════╡\n",
       "│ 31567        ┆ 84     ┆ [540, 31567]  ┆ [2.059909, ┆ [1, 2]      ┆ [4.185226, 4.343543] │\n",
       "│              ┆        ┆               ┆ 3.300911]  ┆             ┆                      │\n",
       "│ 31881        ┆ 84     ┆ [262, 31881]  ┆ [1.272575, ┆ [0, 738]    ┆ [5.03889, 6.998665]  │\n",
       "│              ┆        ┆               ┆ 8.572933]  ┆             ┆                      │\n",
       "│ 31655        ┆ 127    ┆ [1817, 31655] ┆ [4.976245, ┆ [15, 1325]  ┆ [3.17473, 3.348009]  │\n",
       "│              ┆        ┆               ┆ 10.881699] ┆             ┆                      │\n",
       "│ 31569        ┆ 157    ┆ [281, 31569]  ┆ [4.597424, ┆ [5, 8]      ┆ [1.517665, 4.55687]  │\n",
       "│              ┆        ┆               ┆ 4.831842]  ┆             ┆                      │\n",
       "│ 31238        ┆ 157    ┆ [432, 31238]  ┆ [2.048149, ┆ [0, 338]    ┆ [5.06059, 5.027475]  │\n",
       "│              ┆        ┆               ┆ 8.504574]  ┆             ┆                      │\n",
       "│ …            ┆ …      ┆ …             ┆ …          ┆ …           ┆ …                    │\n",
       "│ 31932        ┆ 103405 ┆ [364, 31932]  ┆ [1.693829, ┆ [2, 94]     ┆ [1.680988, 6.278137] │\n",
       "│              ┆        ┆               ┆ 6.449864]  ┆             ┆                      │\n",
       "│ 31671        ┆ 107976 ┆ [1237, 31671] ┆ [4.900066, ┆ [11, 11435] ┆ [4.061255, 4.795384] │\n",
       "│              ┆        ┆               ┆ 14.020318] ┆             ┆                      │\n",
       "│ 31070        ┆ 108539 ┆ [5616, 31070] ┆ [6.594501, ┆ [72, 10883] ┆ [5.804174, 4.513897] │\n",
       "│              ┆        ┆               ┆ 13.775612] ┆             ┆                      │\n",
       "│ 31658        ┆ 113782 ┆ [13, 31658]   ┆ [3.665712, ┆ [1, 6194]   ┆ [7.360681, 6.237061] │\n",
       "│              ┆        ┆               ┆ 12.639827] ┆             ┆                      │\n",
       "│ 31438        ┆ 140870 ┆ [2371, 31438] ┆ [3.202414, ┆ [1, 4757]   ┆ [5.48964, 6.887547]  │\n",
       "│              ┆        ┆               ┆ 10.921802] ┆             ┆                      │\n",
       "└──────────────┴────────┴───────────────┴────────────┴─────────────┴──────────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from tokenizers.processors import ByteLevel as ByteLevelProcessor\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = \"|endoftext|\"\n",
    "\n",
    "# Define the trainer\n",
    "trainer = BpeTrainer(vocab_size=2000, min_frequency=2, special_tokens=[eos_token], show_progress=True)\n",
    "\n",
    "# Define the tokenizer\n",
    "tokenizer = Tokenizer(BPE())\n",
    "\n",
    "# Set up the tokenizer components\n",
    "tokenizer.pre_tokenizer = ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=True)\n",
    "tokenizer.post_processor = ByteLevelProcessor()\n",
    "tokenizer.decoder = ByteLevelDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizers/modified_bpe/data/test_small.txt\") as fl:\n",
    "    lines = fl.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0710045bea23444e94840a517c986852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_docs = 10_000\n",
    "batch_size = 1_000\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", streaming=True, cache_dir=\".data_cache\"\n",
    ")\n",
    "dataset = dataset.take(num_docs).select_columns([\"text\"]).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train_from_iterator(iter(x[\"text\"] for x in dataset), trainer, int(num_docs / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_with_vocab_size(path: str | Path, vocab_size: int) -> PreTrainedTokenizerFast:\n",
    "    path = Path(path)\n",
    "\n",
    "    # Edit conf to adapt to the new vocab_size\n",
    "    conf = srsly.read_json(path / \"tokenizer.json\")\n",
    "    len_alphabet = len(conf[\"model\"][\"vocab\"]) - len(conf[\"model\"][\"merges\"])\n",
    "    conf[\"model\"][\"vocab\"] = dict(list(conf[\"model\"][\"vocab\"].items())[:vocab_size])\n",
    "    conf[\"model\"][\"merges\"] = conf[\"model\"][\"merges\"][: vocab_size - len_alphabet]\n",
    "\n",
    "    # Instantiate tokenizer using tokenizers library\n",
    "    backend_tok = Tokenizer.from_str(json.dumps(conf))\n",
    "    eos_token = srsly.read_yaml(path / \"metadata.yaml\")[\"eos_token\"]\n",
    "\n",
    "    # Instantiate PreTrainedTokenizerFast from object\n",
    "    # NOTE: we do not instantiate from file directly due to compatibility\n",
    "    # https://github.com/huggingface/tokenizers/issues/1562#issuecomment-2315349846\n",
    "    tok = PreTrainedTokenizerFast(tokenizer_object=backend_tok)\n",
    "    tok.padding_side = \"left\"\n",
    "    tok.eos_token = eos_token\n",
    "\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"outputs/tokenizers/2024-08-28T16-34-11\")\n",
    "vocab_size = 500\n",
    "\n",
    "tok = load_tokenizer_with_vocab_size(path, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('outputs/tokenizers/2024-08-28T16-34-11/tok-vocab500/tokenizer_config.json',\n",
       " 'outputs/tokenizers/2024-08-28T16-34-11/tok-vocab500/special_tokens_map.json',\n",
       " 'outputs/tokenizers/2024-08-28T16-34-11/tok-vocab500/tokenizer.json')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.save_pretrained(path / f\"tok-vocab{vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "\n",
    "# edit conf to adapt to the new vocab_size\n",
    "conf = srsly.read_json(path / \"tokenizer.json\")\n",
    "# conf[\"padding\"] = \"left\"\n",
    "len_alphabet = len(conf[\"model\"][\"vocab\"]) - len(conf[\"model\"][\"merges\"])\n",
    "\n",
    "conf[\"model\"][\"vocab\"] = dict(list(conf[\"model\"][\"vocab\"].items())[:vocab_size])\n",
    "conf[\"model\"][\"merges\"] = conf[\"model\"][\"merges\"][: vocab_size - len_alphabet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer.from_str(json.dumps(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['type', 'dropout', 'unk_token', 'continuing_subword_prefix', 'end_of_word_suffix', 'fuse_unk', 'byte_fallback', 'ignore_merges', 'vocab', 'merges'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf[\"model\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curvature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
