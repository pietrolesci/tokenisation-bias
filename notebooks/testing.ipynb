{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data from Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43b15f8c13ec457e9078ff2ec9895c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9ad99ba47e43d9ae37c7576fa34af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)minipile/000_bpe8064minipile.ds.metadata:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e258dda485124d06b5d808d65079ddfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)8064minipile/bpe8064minipile.ds.metadata:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b406c1e433ca40b4bc6796eddd414463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "000_bpe8064minipile.ds.index:   0%|          | 0.00/8.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae6c77844c342dbbe70afd760effe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "000_bpe8064minipile.ds:   0%|          | 0.00/4.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/pl487/rdd/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "dataset = \"pietrolesci/minipile\"  # \"pietrolesci/fineweb-edu-10BT\"\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=dataset, repo_type=\"dataset\", local_dir=\"data\", allow_patterns=\"bpe8064minipile/*\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datatrove.utils.dataset import DatatroveFolderDataset\n",
    "import polars as pl\n",
    "ds = DatatroveFolderDataset(\n",
    "    folder_path=\"data/minipile-eval/bpe32000minipile\",\n",
    "    filename_pattern=\"data/minipile-eval/bpe32000minipile/*.ds\",\n",
    "    seq_len=2048,\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    "    token_size=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet(\"/home/pl487/rdd/data/minipile-eval-bpe32000minipile.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_500, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>uid</th><th>input_ids</th></tr><tr><td>u64</td><td>list[i32]</td></tr></thead><tbody><tr><td>0</td><td>[49, 26, … 199]</td></tr><tr><td>1</td><td>[14795, 199, … 199]</td></tr><tr><td>2</td><td>[2011, 1164, … 14]</td></tr><tr><td>3</td><td>[16472, 17611, … 14]</td></tr><tr><td>4</td><td>[4265, 258, … 199]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>10495</td><td>[13723, 26311, … 13425]</td></tr><tr><td>10496</td><td>[15, 10, … 199]</td></tr><tr><td>10497</td><td>[14906, 415, … 199]</td></tr><tr><td>10498</td><td>[18019, 26, … 31]</td></tr><tr><td>10499</td><td>[17, 14, … 14]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_500, 2)\n",
       "┌───────┬─────────────────────────┐\n",
       "│ uid   ┆ input_ids               │\n",
       "│ ---   ┆ ---                     │\n",
       "│ u64   ┆ list[i32]               │\n",
       "╞═══════╪═════════════════════════╡\n",
       "│ 0     ┆ [49, 26, … 199]         │\n",
       "│ 1     ┆ [14795, 199, … 199]     │\n",
       "│ 2     ┆ [2011, 1164, … 14]      │\n",
       "│ 3     ┆ [16472, 17611, … 14]    │\n",
       "│ 4     ┆ [4265, 258, … 199]      │\n",
       "│ …     ┆ …                       │\n",
       "│ 10495 ┆ [13723, 26311, … 13425] │\n",
       "│ 10496 ┆ [15, 10, … 199]         │\n",
       "│ 10497 ┆ [14906, 415, … 199]     │\n",
       "│ 10498 ┆ [18019, 26, … 31]       │\n",
       "│ 10499 ┆ [17, 14, … 14]          │\n",
       "└───────┴─────────────────────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.from_dicts(\n",
    "    iter({\"doc_idx\": idx, \"input_ids\": doc[\"input_ids\"].tolist()[1:]} for idx, doc in enumerate(ds)),\n",
    "    schema=[('doc_idx', pl.UInt64), ('input_ids', pl.List(pl.UInt16))],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_959, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>doc_idx</th><th>input_ids</th></tr><tr><td>u64</td><td>list[u16]</td></tr></thead><tbody><tr><td>0</td><td>[26, 199, … 93]</td></tr><tr><td>1</td><td>[91, 74, … 199]</td></tr><tr><td>2</td><td>[29968, 10717, … 4]</td></tr><tr><td>3</td><td>[472, 436, … 62]</td></tr><tr><td>4</td><td>[10, 75, … 60]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>8954</td><td>[2373, 30557, … 290]</td></tr><tr><td>8955</td><td>[18828, 392, … 279]</td></tr><tr><td>8956</td><td>[8804, 22974, … 13]</td></tr><tr><td>8957</td><td>[13, 73, … 264]</td></tr><tr><td>8958</td><td>[2621, 63, … 584]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8_959, 2)\n",
       "┌─────────┬──────────────────────┐\n",
       "│ doc_idx ┆ input_ids            │\n",
       "│ ---     ┆ ---                  │\n",
       "│ u64     ┆ list[u16]            │\n",
       "╞═════════╪══════════════════════╡\n",
       "│ 0       ┆ [26, 199, … 93]      │\n",
       "│ 1       ┆ [91, 74, … 199]      │\n",
       "│ 2       ┆ [29968, 10717, … 4]  │\n",
       "│ 3       ┆ [472, 436, … 62]     │\n",
       "│ 4       ┆ [10, 75, … 60]       │\n",
       "│ …       ┆ …                    │\n",
       "│ 8954    ┆ [2373, 30557, … 290] │\n",
       "│ 8955    ┆ [18828, 392, … 279]  │\n",
       "│ 8956    ┆ [8804, 22974, … 13]  │\n",
       "│ 8957    ┆ [13, 73, … 264]      │\n",
       "│ 8958    ┆ [2621, 63, … 584]    │\n",
       "└─────────┴──────────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (100_708, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>doc_idx</th><th>token_logprob</th></tr><tr><td>u64</td><td>list[f64]</td></tr></thead><tbody><tr><td>0</td><td>[-5.496313, -1.223472, … -3.696448]</td></tr><tr><td>1</td><td>[-4.776392, -5.827122, … -9.259767]</td></tr><tr><td>2</td><td>[-3.334471, -5.524037, … -9.588385]</td></tr><tr><td>3</td><td>[-2.233987, -2.724483, … -2.002547]</td></tr><tr><td>4</td><td>[-7.793006, -2.564259, … -7.019312]</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>100703</td><td>[-7.126338, -3.591892, -9.701439]</td></tr><tr><td>100704</td><td>[-9.839044, -0.144264, -5.004041]</td></tr><tr><td>100705</td><td>[-2.172212, -12.078355, -6.290206]</td></tr><tr><td>100706</td><td>[-7.815956, -2.294855, -1.295988]</td></tr><tr><td>100707</td><td>[-11.12728, -0.112901, -8.11306]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (100_708, 2)\n",
       "┌─────────┬─────────────────────────────────┐\n",
       "│ doc_idx ┆ token_logprob                   │\n",
       "│ ---     ┆ ---                             │\n",
       "│ u64     ┆ list[f64]                       │\n",
       "╞═════════╪═════════════════════════════════╡\n",
       "│ 0       ┆ [-5.496313, -1.223472, … -3.69… │\n",
       "│ 1       ┆ [-4.776392, -5.827122, … -9.25… │\n",
       "│ 2       ┆ [-3.334471, -5.524037, … -9.58… │\n",
       "│ 3       ┆ [-2.233987, -2.724483, … -2.00… │\n",
       "│ 4       ┆ [-7.793006, -2.564259, … -7.01… │\n",
       "│ …       ┆ …                               │\n",
       "│ 100703  ┆ [-7.126338, -3.591892, -9.7014… │\n",
       "│ 100704  ┆ [-9.839044, -0.144264, -5.0040… │\n",
       "│ 100705  ┆ [-2.172212, -12.078355, -6.290… │\n",
       "│ 100706  ┆ [-7.815956, -2.294855, -1.2959… │\n",
       "│ 100707  ┆ [-11.12728, -0.112901, -8.1130… │\n",
       "└─────────┴─────────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(data, on=\"doc_idx\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode([\"token_logprob\", \"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    tok_pos=pl.int_range(0, pl.len()).over(pl.col(\"doc_idx\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_959, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>doc_idx</th><th>tok_pos</th></tr><tr><td>u64</td><td>i64</td></tr></thead><tbody><tr><td>8685</td><td>2047</td></tr><tr><td>1325</td><td>2047</td></tr><tr><td>5389</td><td>2047</td></tr><tr><td>6571</td><td>2047</td></tr><tr><td>143</td><td>2047</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>3659</td><td>2047</td></tr><tr><td>8607</td><td>2047</td></tr><tr><td>3501</td><td>2047</td></tr><tr><td>5210</td><td>2047</td></tr><tr><td>5368</td><td>2047</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8_959, 2)\n",
       "┌─────────┬─────────┐\n",
       "│ doc_idx ┆ tok_pos │\n",
       "│ ---     ┆ ---     │\n",
       "│ u64     ┆ i64     │\n",
       "╞═════════╪═════════╡\n",
       "│ 8685    ┆ 2047    │\n",
       "│ 1325    ┆ 2047    │\n",
       "│ 5389    ┆ 2047    │\n",
       "│ 6571    ┆ 2047    │\n",
       "│ 143     ┆ 2047    │\n",
       "│ …       ┆ …       │\n",
       "│ 3659    ┆ 2047    │\n",
       "│ 8607    ┆ 2047    │\n",
       "│ 3501    ┆ 2047    │\n",
       "│ 5210    ┆ 2047    │\n",
       "│ 5368    ┆ 2047    │\n",
       "└─────────┴─────────┘"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group_by(\"doc_idx\").agg(pl.col(\"tok_pos\").max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>value</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>1.8348032e7</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>-2.340418</td></tr><tr><td>&quot;std&quot;</td><td>2.833773</td></tr><tr><td>&quot;min&quot;</td><td>-27.031298</td></tr><tr><td>&quot;25%&quot;</td><td>-3.854038</td></tr><tr><td>&quot;50%&quot;</td><td>-1.142672</td></tr><tr><td>&quot;75%&quot;</td><td>-0.047235</td></tr><tr><td>&quot;max&quot;</td><td>0.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 2)\n",
       "┌────────────┬─────────────┐\n",
       "│ statistic  ┆ value       │\n",
       "│ ---        ┆ ---         │\n",
       "│ str        ┆ f64         │\n",
       "╞════════════╪═════════════╡\n",
       "│ count      ┆ 1.8348032e7 │\n",
       "│ null_count ┆ 0.0         │\n",
       "│ mean       ┆ -2.340418   │\n",
       "│ std        ┆ 2.833773    │\n",
       "│ min        ┆ -27.031298  │\n",
       "│ 25%        ┆ -3.854038   │\n",
       "│ 50%        ┆ -1.142672   │\n",
       "│ 75%        ┆ -0.047235   │\n",
       "│ max        ┆ 0.0         │\n",
       "└────────────┴─────────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"token_logprob\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_048, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>tok_pos</th><th>len</th></tr><tr><td>i64</td><td>u64</td></tr></thead><tbody><tr><td>1460</td><td>1973</td></tr><tr><td>1557</td><td>1982</td></tr><tr><td>1695</td><td>1988</td></tr><tr><td>1444</td><td>1996</td></tr><tr><td>1937</td><td>1996</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>4</td><td>3673</td></tr><tr><td>3</td><td>3795</td></tr><tr><td>2</td><td>4137</td></tr><tr><td>1</td><td>4663</td></tr><tr><td>0</td><td>5709</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_048, 2)\n",
       "┌─────────┬──────┐\n",
       "│ tok_pos ┆ len  │\n",
       "│ ---     ┆ ---  │\n",
       "│ i64     ┆ u64  │\n",
       "╞═════════╪══════╡\n",
       "│ 1460    ┆ 1973 │\n",
       "│ 1557    ┆ 1982 │\n",
       "│ 1695    ┆ 1988 │\n",
       "│ 1444    ┆ 1996 │\n",
       "│ 1937    ┆ 1996 │\n",
       "│ …       ┆ …    │\n",
       "│ 4       ┆ 3673 │\n",
       "│ 3       ┆ 3795 │\n",
       "│ 2       ┆ 4137 │\n",
       "│ 1       ┆ 4663 │\n",
       "│ 0       ┆ 5709 │\n",
       "└─────────┴──────┘"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df.filter(pl.col(\"token_logprob\") < -4)\n",
    "    .group_by(\"tok_pos\").agg(pl.len())\n",
    "    .sort(\"len\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/home/pl487/rdd/outputs/model_train_pl/smol_llama-81M-tied_bpe32000minipile_2024-09-30T19-42-18/.checkpoints/step0\"\n",
    ")\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 768)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=768, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((768,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((768,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((768,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(DataLoader(ds, batch_size=5, shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.45. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    labels = input_ids.clone()\n",
    "    loss1 = model(input_ids=input_ids, labels=labels).loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    input_ids = batch[\"input_ids\"][:, :-1]\n",
    "    labels = batch[\"input_ids\"][:, 1:]\n",
    "    logits = model.forward(input_ids=input_ids).logits\n",
    "    loss2 = torch.nn.functional.cross_entropy(logits.permute(0, 2, 1), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_parquet(\"/home/pl487/rdd/data/slim-pajama-eval-bpe32000/data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.select_columns([\"uid\", \"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fc21495fc6457ebf767ce8a9f58887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"/home/pl487/rdd/data/slim-pajama-eval-bpe32000/validation_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/home/pl487/rdd/data/slim-pajama-eval-bpe32000/validation_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_polars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.with_columns(pl.col(\"input_ids\").list.slice(0, 2049))\n",
    "    .with_columns(len=pl.col(\"input_ids\").list.len())\n",
    "    .sort(\"len\", descending=True)\n",
    "    .drop(\"len\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_polars(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be94a5d0f5034905ae30caab91617d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(\"/home/pl487/rdd/data/slim-pajama-eval-bpe32000/validation_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     20000.000000\n",
       "mean       1112.514700\n",
       "std        7862.181971\n",
       "min          24.000000\n",
       "25%         205.000000\n",
       "50%         482.000000\n",
       "75%         983.000000\n",
       "max      752280.000000\n",
       "Name: input_ids, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pds[\"input_ids\"].map(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check eval dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import srsly\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from IPython.display import HTML, display\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"data/minipile-eval-bpe32000minipile/eval_samples/\")\n",
    "tok = AutoTokenizer.from_pretrained(\"outputs/tokenizers/bpe32000minipile/\")\n",
    "df = pl.from_arrow(ds.data.table)\n",
    "merges_df = (\n",
    "    pl.DataFrame(srsly.read_jsonl(\"outputs/tok_train/bpe_minipile_2024-09-22T17-58-54/implemented_merges.jsonl\"))\n",
    "    .with_columns(pl.col(\"new_token_id\").cast(pl.Int32))\n",
    ")\n",
    "\n",
    "def decode_sequence(tok, input_ids: list[int], highlight_ids: list[int], highlight_color: str = \"green\") -> None:\n",
    "    # Convert token IDs to tokens\n",
    "    tokens = tok.convert_ids_to_tokens(input_ids, skip_special_tokens=False)\n",
    "\n",
    "    # Highlight tokens that are in highlight_ids\n",
    "    highlighted_tokens = [\n",
    "        f\"<span style='background-color:{highlight_color}'>{tok}</span>\" if input_ids[i] in highlight_ids else tok\n",
    "        for i, tok in enumerate(tokens)\n",
    "    ]\n",
    "\n",
    "    # Convert tokens back to a single string\n",
    "    decoded_string = tok.convert_tokens_to_string(highlighted_tokens)\n",
    "\n",
    "    # Display the result in Jupyter notebook\n",
    "    display(HTML(decoded_string))\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     \"/home/pl487/rdd/outputs/model_train/pythia-9M-bpe32000/checkpoints/checkpoint-50000\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/pl487/rdd/data/minipile-eval-bpe32000minipile/\")\n",
    "df = pl.concat([\n",
    "    pl.read_parquet(data_path / \"in_vocab_samples.parquet\"),\n",
    "    # pl.read_parquet(data_path / \"out_vocab_samples.parquet\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort(\"new_token_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " The familiar breeds of dogs, cattle, chickens, and food plants have been obtained by this process of selection practiced by people with particular objectives.\n",
       "\n",
       "The ensuing chapters (II–VIII) of The Origin extend the argument to variations propagated by natural selection for the benefit of the organisms themselves rather than by artificial selection of traits desired by humans. As a consequence of natural selection, organisms exhibit design, that is, exhibit adaptive organs and functions. The design of organisms as they exist in nature, however, is not “intelligent design,” imposed by God as a Supreme Engineer or by humans; rather, it is the result of a natural process of selection, promoting the adaptation of organisms to their environments. This is how natural selection works: Individuals that have beneficial variations, that is, variations that improve their probability of survival and reproduction, leave more descendants than individuals of the same species that have less beneficial variations. The beneficial variations will consequently increase in frequency over the generations; less beneficial or harmful variations will be eliminated from the species. Eventually, all individuals of the species will have the beneficial features; new features will arise over eons of time.\n",
       "\n",
       "Organisms exhibit complex design, but it is not, in current language, “irreducible complexity,” emerging all of a sudden in full bloom. Rather, according to Darwin's theory of natural selection, the design has arisen gradually and cumulatively, step by step, promoted by the reproductive success of individuals with incrementally more adaptive elaborations.\n",
       "\n",
       "It follows from Darwin's explanation of adaptation that evolution must necessarily occur as a consequence of organisms becoming adapted to different environments in different localities and to the ever-changing conditions of the environment over time, and as hereditary variations become available at a particular time that improve, in that place and at that time, the organisms' chances of survival and reproduction. The Origin's evidence for biological evolution is central to Darwin's explanation of design, because this explanation implies that biological evolution occurs, which Darwin therefore seeks to demonstrate in most of the remainder of the book (ref. 1, Chapters IX–XIII).\n",
       "\n",
       "In the concluding Chapter XIV of The Origin, Darwin returns to the dominant theme of adaptation and design. In an eloquent final paragraph, Darwin asserts the “grandeur” of his vision: “It is interesting to contemplate an entangled bank, clothed with many plants of many kinds, with birds singing on the bushes, with various insects flitting about, and with worms crawling through the damp earth, and to reflect that these elaborately constructed forms, so different from each other, and dependent on each other in so complex a manner, have all been produced by laws acting around us…. Thus, from the war of nature, from famine and death, the most exalted object which we are capable of conceiving, namely, the production of the higher animals, directly follows. There is grandeur in this view of life, with its several powers, having been originally breathed into a few forms or into one; and that, whilst this planet has gone cycling on according to the fixed law of gravity, from so simple a beginning endless forms most beautiful and most wonderful have been, and are being, evolved” (ref. 1, p. 489–490; emphasis added).\n",
       "\n",
       "Darwin's Origin addresses the same issue as Paley: how to account for the adaptive configuration of organisms and their parts, which are so obviously designed to fulfill certain functions. Darwin argues that hereditary adaptive variations (“variations useful in some way to each being”) occasionally appear, and that these are likely to increase the reproductive chances of their carriers. The success of pigeon fanciers and animal breeders clearly shows the occasional occurrence of useful hereditary variations. In nature, over the generations, Darwin's argument continues, favorable variations will be preserved, multiplied, and conjoined; injurious ones will be eliminated. In one place, Darwin avers: “I can see no limit to this power [natural selection] in slowly and beautifully adapting each form to the most complex relations of life” (ref. 1, p. 469).\n",
       "\n",
       "In his Autobiography, Darwin wrote, “The old argument of design in nature, as given by Paley, which formerly seemed to me so conclusive, falls, now that the law of natural selection has been discovered. We can no longer argue that, for instance, the beautiful hinge of a bivalve shell must have been made by an intelligent being, like the hinge of a door by a man” (11).\n",
       "\n",
       "Natural selection was proposed by Darwin primarily to account for the adaptive organization, or design, of living beings; it is a process that preserves and promotes adaptation. Evolutionary change through time and evolutionary diversification (multiplication of species) often ensue as by-products of natural selection fostering the adaptation of organisms to their milieu. Evolutionary change is not directly promoted by natural selection, however, and therefore it is not its necessary consequence. Indeed, some species may remain unchanged for long periods of time, as Darwin noted. Nautilus, Lingula, and other so-called “living fossils” are Darwin's examples of organisms that have remained unchanged in their appearance for millions of years.\n",
       "\n",
       "Mutation and Natural Selection\n",
       "\n",
       "Evolution affects all aspects of an organism's life: morphology (form and structure), physiology (function), behavior, and ecology (interaction with the environment). Underlying these changes are changes in the hereditary materials. Hence, in genetic terms, evolution consists of changes in the organisms' hereditary makeup.\n",
       "\n",
       "Evolution can be seen as a two-step process. First, hereditary variation arises by mutation; second, selection occurs by which useful variations increase in frequency and those that are less useful or injurious are eliminated over the generations. “Useful” and “injurious” are terms used by Darwin in his definition of natural selection. The significant point is that individuals having useful variations “would have the best chance of surviving and procreating their kind” (ref. 1, p. 81). As a consequence, useful variations increase in frequency over the generations, at the expense of those that are less useful or injurious.\n",
       "\n",
       "The process of mutation provides each generation with many new genetic variations, in addition to those carried over from previous generations. Thus, it is not surprising to see that, when new environmental challenges arise, species are able to adapt to them. More than 200 insect and rodent species, for example, developed resistance to DDT, Warfarin, and other pesticides in places where spraying was intense. Although these animals had never before encountered these synthetic compounds, mutations allowed some individuals to survive in their presence. These individuals reproduced and, thus, the mutations providing resistance increased in frequency over the generations, so that eventually the population was no longer susceptible to the pesticide. The adaptation had come about by the combined processes of mutation and natural selection.\n",
       "\n",
       "The resistance of disease-causing bacteria and parasites to antibiotics and other drugs is a consequence of the same process. When an individual receives an antibiotic that specifically kills the bacteria causing a disease—say, tuberculosis—the immense majority of the bacteria die, but one in several million may have a mutation that provides resistance to the antibiotic. These resistant bacteria survive, multiply, and spread from individual to individual. Eventually, the antibiotic no longer cures the disease in most or all people because the bacteria are resistant. This is why modern medicine treats bacterial diseases with cocktails of antibiotics. If the incidence of a mutation conferring resistance to a given antibiotic is one in a million, the probability of one bacterium carrying three mutations, each conferring resistance to one of three antibiotics, is one in a quintillion (one in a million million million). Even at the peak of infection, when billions or trillions of bacteria exist in a sick person, it is not likely, if not altogether impossible, that any bacteria resistant to all three antibiotics will occur in any infected individual.\n",
       "\n",
       "Natural selection is much more than a “purifying” process, for it is able to generate novelty by increasing the probability of otherwise extremely improbable genetic combinations. Natural selection in combination with mutation becomes, in this respect, a creative process. Moreover, it is a process that has been occurring for many millions of years in many different evolutionary lineages and a multitude of species, each consisting of a large number of individuals. Evolution by mutation and natural selection has produced the enormous diversity of the living world with its wondrous adaptations.\n",
       "\n",
       "Several hundred million generations separate modern animals from the early animals of the Cambrian geological period (542 million years ago). The number of mutations that can be tested, and those eventually selected, in millions of individual animals over millions of generations is difficult for a human mind to fathom, but we can readily understand that the accumulation of millions of small, functionally advantageous changes could yield remarkably complex and adaptive organs, such as the eye.\n",
       "\n",
       "Natural selection is an incremental process, operating over time and yielding organisms better able to survive and reproduce than others. Individuals of a given species differ from one another at any one time only in small ways; for example, the difference between bacteria that have or lack an enzyme able to synthesize the sugar lactose or between moths that have light or dark wings. These differences typically involve one or only a few genes, but they can make the difference between survival or death, as in the resistance to DDT or to antibiotics. Consider a different sort of example. Some pocket mice (Chaetodipus intermedius) live in rocky outcrops in Arizona. Light, sandy-colored mice are found in light-colored habitats, whereas dark (melanic) mice prevail in dark rocks formed from ancient flows of basaltic lava. The match between background and fur color protects the mice from avian and mammal predators that hunt guided largely by vision. Mutations in one single gene (coding for the melanocortin-1-receptor, represented as MC1R) account for the difference between light and dark pelage (12).\n",
       "\n",
       "<span style='background-color:green'>Adapt</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_ids = df[12][\"context\"].to_list()[0]\n",
    "decode_sequence(tok, input_ids, [input_ids[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort(\"new_token_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_965, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_token_id</th><th>len</th></tr><tr><td>i32</td><td>u64</td></tr></thead><tbody><tr><td>33322</td><td>13</td></tr><tr><td>32926</td><td>11</td></tr><tr><td>33188</td><td>15</td></tr><tr><td>32423</td><td>5</td></tr><tr><td>31738</td><td>3</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>30532</td><td>38</td></tr><tr><td>31300</td><td>14</td></tr><tr><td>33161</td><td>70</td></tr><tr><td>32625</td><td>37</td></tr><tr><td>33283</td><td>8</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_965, 2)\n",
       "┌──────────────┬─────┐\n",
       "│ new_token_id ┆ len │\n",
       "│ ---          ┆ --- │\n",
       "│ i32          ┆ u64 │\n",
       "╞══════════════╪═════╡\n",
       "│ 33322        ┆ 13  │\n",
       "│ 32926        ┆ 11  │\n",
       "│ 33188        ┆ 15  │\n",
       "│ 32423        ┆ 5   │\n",
       "│ 31738        ┆ 3   │\n",
       "│ …            ┆ …   │\n",
       "│ 30532        ┆ 38  │\n",
       "│ 31300        ┆ 14  │\n",
       "│ 33161        ┆ 70  │\n",
       "│ 32625        ┆ 37  │\n",
       "│ 33283        ┆ 8   │\n",
       "└──────────────┴─────┘"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.group_by(\"new_token_id\").agg(pl.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_token_id</th><th>uid</th><th>input_ids</th></tr><tr><td>i32</td><td>u64</td><td>list[i32]</td></tr></thead><tbody><tr><td>33499</td><td>9133</td><td>[49, 26, … 1135]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌──────────────┬──────┬──────────────────┐\n",
       "│ new_token_id ┆ uid  ┆ input_ids        │\n",
       "│ ---          ┆ ---  ┆ ---              │\n",
       "│ i32          ┆ u64  ┆ list[i32]        │\n",
       "╞══════════════╪══════╪══════════════════╡\n",
       "│ 33499        ┆ 9133 ┆ [49, 26, … 1135] │\n",
       "└──────────────┴──────┴──────────────────┘"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2049])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.tensor(ds[:3][\"input_ids\"], dtype=torch.long)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tok_path = Path(\"/home/pl487/rdd/outputs/tokenizers/bpe32000/\")\n",
    "tok = AutoTokenizer.from_pretrained(raw_tok_path)\n",
    "prefix_map = {d[\"prefix\"]: d[\"new_token_id\"] for d in srsly.read_jsonl(raw_tok_path / \"prefix_map_bpe32000.jsonl\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_mapping = [\n",
    "#     prefix_map.get(t, []) + [t] if (i + 1) % 2 == 0 else [t] for i, t in enumerate(batch[:, -2:].flatten().tolist())\n",
    "# ]\n",
    "batch_mapping: list[tuple[int, list[int]]] = []\n",
    "for penultimate_token, last_token in batch[:, -2:].unbind():\n",
    "    # penultimate token only needs itself (always)\n",
    "    m_penultimate = penultimate_token.item()\n",
    "\n",
    "    # for the last token we apply the trick\n",
    "    m_last = [last_token.item()] + prefix_map.get(last_token.item(), [])\n",
    "\n",
    "    batch_mapping.append((m_penultimate, m_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' I', ' said', ',', ' \"', 'Why', ' would', ' you', ' leave', ' Ann', ' Arbor']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.45. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/internal/generation_utils#transformers.Cache)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    logits = model.forward(input_ids=batch[:, :-1]).logits\n",
    "    probs = logits.softmax(-1)\n",
    "\n",
    "last_tokens_probs = probs[:, -2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' I', ' said', ',', ' \"', 'Why', ' would', ' you', ' leave', ' Ann', ' Arbor']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.batch_decode(batch.numpy()[0, -10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' He', \"'m\", ',', ' \"', 'I', ' is', ' you', ' like', ' the', 'ie']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.batch_decode(logits[0, -10:].argmax(-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros_like(last_tokens_probs)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.zeros_like(last_tokens_probs)\n",
    "for idx, (m_penultimate, m_last) in enumerate(batch_mapping):\n",
    "    # penultimate token only gets its position\n",
    "    mask[idx, -2, m_penultimate] = 1.0\n",
    "\n",
    "    # last token gets the fix\n",
    "    mask[idx, -1, m_last] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check it gets the correct eleements\n",
    "batch_mapping, (last_tokens_probs * mask).nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(last_tokens_probs * mask).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(len, batch_mapping)), mask.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_ids = t[:, -2:]\n",
    "last_token_logprobs = logprobs[:, -2:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = last_token_ids.clone().flatten().cpu().numpy().tolist()\n",
    "it = last_token_logprobs.reshape(-1, last_token_logprobs.shape[-1])\n",
    "\n",
    "out = []\n",
    "for idx, tok in enumerate(tokens):\n",
    "    # Take other tokens where tok is a prefix + itself\n",
    "    ids = prefix_map.get(tok, []) + [tok]\n",
    "    o = it[idx, ids]\n",
    "    out.append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logprobs.reshape(-1, last_token_logprobs.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = torch.zeros_like(last_token_logprobs).reshape(last_token_logprobs.shape[0], -1)\n",
    "mask = torch.zeros_like(last_token_logprobs).reshape(-1)\n",
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = last_token_ids.clone().flatten().cpu().numpy().tolist()\n",
    "\n",
    "pos = []\n",
    "for tok in tokens:\n",
    "    # Take other tokens where tok is a prefix + itself\n",
    "    pos.append(prefix_map.get(tok, []) + [tok])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_ids.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch, token_position_in_seq, token_position_in_vocab\n",
    "logprobs[0, -2, 6106], logprobs[0, -1, 30681]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size, seq_len, added\n",
    "last_token_ids = t[:, -2:].unsqueeze(-1)\n",
    "print(last_token_ids.shape)\n",
    "last_token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logprobs = logprobs[:, -2:, :]\n",
    "print(last_token_logprobs.shape)\n",
    "last_token_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = last_token_logprobs.take_along_dim(dim=-1, indices=last_token_ids)\n",
    "print(res.shape)\n",
    "res.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logprobs[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_map = {6016: [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[..., -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t[..., -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[0], [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?torch.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = torch.nn.functional.cross_entropy(shift_logits.permute(0, 2, 1), shift_labels, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [np.pad([1, 2, 3], (2, 0), constant_values=0), np.pad([1, 2, 3], (2, 0), constant_values=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.vstack(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pl.read_parquet(\"/home/pl487/rdd/outputs/model_eval/2024-09-11T11-06-11/pythia-9M-bpe32000.parquet\")\n",
    "b = pl.read_parquet(\"/home/pl487/rdd/outputs/model_eval/2024-09-11T11-31-36/pythia-9M-bpe32000.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.join(b, on=[\"uid\", \"new_token_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.decoders import ByteLevel as ByteLevelDecoder\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import ByteLevel\n",
    "from tokenizers.processors import ByteLevel as ByteLevelProcessor\n",
    "from tokenizers.trainers import BpeTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = \"|endoftext|\"\n",
    "\n",
    "# Define the trainer\n",
    "trainer = BpeTrainer(vocab_size=2000, min_frequency=2, special_tokens=[eos_token], show_progress=True)\n",
    "\n",
    "# Define the tokenizer\n",
    "tokenizer = Tokenizer(BPE())\n",
    "\n",
    "# Set up the tokenizer components\n",
    "tokenizer.pre_tokenizer = ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=True)\n",
    "tokenizer.post_processor = ByteLevelProcessor()\n",
    "tokenizer.decoder = ByteLevelDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tokenizers/modified_bpe/data/test_small.txt\") as fl:\n",
    "    lines = fl.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_docs = 10_000\n",
    "batch_size = 1_000\n",
    "\n",
    "dataset = load_dataset(\n",
    "    \"HuggingFaceFW/fineweb-edu\", \"sample-10BT\", split=\"train\", streaming=True, cache_dir=\".data_cache\"\n",
    ")\n",
    "dataset = dataset.take(num_docs).select_columns([\"text\"]).batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train_from_iterator(iter(x[\"text\"] for x in dataset), trainer, int(num_docs / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizer_with_vocab_size(path: str | Path, vocab_size: int) -> PreTrainedTokenizerFast:\n",
    "    path = Path(path)\n",
    "\n",
    "    # Edit conf to adapt to the new vocab_size\n",
    "    conf = srsly.read_json(path / \"tokenizer.json\")\n",
    "    len_alphabet = len(conf[\"model\"][\"vocab\"]) - len(conf[\"model\"][\"merges\"])\n",
    "    conf[\"model\"][\"vocab\"] = dict(list(conf[\"model\"][\"vocab\"].items())[:vocab_size])\n",
    "    conf[\"model\"][\"merges\"] = conf[\"model\"][\"merges\"][: vocab_size - len_alphabet]\n",
    "\n",
    "    # Instantiate tokenizer using tokenizers library\n",
    "    backend_tok = Tokenizer.from_str(json.dumps(conf))\n",
    "    eos_token = srsly.read_yaml(path / \"metadata.yaml\")[\"eos_token\"]\n",
    "\n",
    "    # Instantiate PreTrainedTokenizerFast from object\n",
    "    # NOTE: we do not instantiate from file directly due to compatibility\n",
    "    # https://github.com/huggingface/tokenizers/issues/1562#issuecomment-2315349846\n",
    "    tok = PreTrainedTokenizerFast(tokenizer_object=backend_tok)\n",
    "    tok.padding_side = \"left\"\n",
    "    tok.eos_token = eos_token\n",
    "\n",
    "    return tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"outputs/tokenizers/2024-08-28T16-34-11\")\n",
    "vocab_size = 500\n",
    "\n",
    "tok = load_tokenizer_with_vocab_size(path, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.save_pretrained(path / f\"tok-vocab{vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 500\n",
    "\n",
    "# edit conf to adapt to the new vocab_size\n",
    "conf = srsly.read_json(path / \"tokenizer.json\")\n",
    "# conf[\"padding\"] = \"left\"\n",
    "len_alphabet = len(conf[\"model\"][\"vocab\"]) - len(conf[\"model\"][\"merges\"])\n",
    "\n",
    "conf[\"model\"][\"vocab\"] = dict(list(conf[\"model\"][\"vocab\"].items())[:vocab_size])\n",
    "conf[\"model\"][\"merges\"] = conf[\"model\"][\"merges\"][: vocab_size - len_alphabet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tokenizer.from_str(json.dumps(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf[\"model\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.get_vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curvature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
