{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "import srsly\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_path = Path(\"/home/pl487/rdd/outputs/tok_train/bpe_2024-09-04T12-59-54/\")\n",
    "data_path = Path(\"data/slim-pajama-subset-validation/\")\n",
    "vocab_size = 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_type = tok_path.name.split(\"_\")[0]\n",
    "assert tok_type in (\"bpe\",)\n",
    "\n",
    "tok_name = f\"{tok_type}{vocab_size}\"\n",
    "out_path = data_path.parent / f\"{data_path.name}-sample-{tok_name}\"\n",
    "out_path.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    pl.scan_parquet(f\"hf://datasets/pietrolesci/slim-pajama-subset-validation/bpe{vocab_size}/train-*.parquet\")\n",
    "    .with_columns(tok_pos=pl.int_ranges(pl.col(\"input_ids\").list.len()), seq_len=pl.col(\"input_ids\").list.len())\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merges = pl.DataFrame(srsly.read_jsonl(tok_path / \"implemented_merges.jsonl\")).with_columns(\n",
    "    pl.col(\"new_token_id\").cast(pl.Int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get window around cutoff\n",
    "num_tok_window = 5_000\n",
    "df = merges.filter(\n",
    "    (pl.col(\"new_token_id\") >= vocab_size - num_tok_window) & (pl.col(\"new_token_id\") < vocab_size + num_tok_window)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab = df.filter(pl.col(\"new_token_id\") < vocab_size)\n",
    "out_vocab = df.filter(pl.col(\"new_token_id\") >= vocab_size)\n",
    "\n",
    "out_vocab = (\n",
    "    out_vocab.with_columns(pl.col(\"pair\").list.to_struct())\n",
    "    .unnest(\"pair\")\n",
    "    .rename({\"field_0\": \"tok_a\", \"field_1\": \"tok_b\"})\n",
    "    .with_columns(pl.col(\"tok_a\").cast(pl.Int32), pl.col(\"tok_b\").cast(pl.Int32))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get document uid and position of the token in doc for tokens in vocab\n",
    "in_vocab_index = in_vocab.select([\"new_token_id\"]).join(\n",
    "    data.explode([\"input_ids\", \"tok_pos\"]), left_on=\"new_token_id\", right_on=\"input_ids\", how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vocab_index = (\n",
    "    out_vocab.select([\"tok_a\", \"tok_b\", \"new_token_id\"])\n",
    "    .join(\n",
    "        data.explode([\"input_ids\", \"tok_pos\"]).with_columns(next_input_id=pl.col(\"input_ids\").shift(-1)),\n",
    "        left_on=[\"tok_a\", \"tok_b\"],\n",
    "        right_on=[\"input_ids\", \"next_input_id\"],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .rename({\"tok_pos\": \"tok_pos_a\"})\n",
    "    .with_columns(tok_pos_b=pl.col(\"tok_pos_a\") + 1)\n",
    "    .filter(pl.col(\"tok_pos_b\") < pl.col(\"seq_len\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get docs per each token\n",
    "num_samples = 100\n",
    "\n",
    "in_vocab_sample = in_vocab_index.filter(\n",
    "    # https://stackoverflow.com/a/72636610\n",
    "    pl.int_range(pl.len()).shuffle(seed=42).over(\"new_token_id\") < num_samples\n",
    ")\n",
    "\n",
    "out_vocab_sample = out_vocab_index.filter(\n",
    "    # https://stackoverflow.com/a/72636610\n",
    "    pl.int_range(pl.len()).shuffle(seed=42).over(\"new_token_id\") < num_samples\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from each doc, get the context (with the token appended) of the required size (+1, since the token is appended)\n",
    "# context_length = 2048\n",
    "context_length = 256\n",
    "\n",
    "in_vocab_df = (\n",
    "    in_vocab_sample.join(data.select([\"uid\", \"input_ids\"]), on=\"uid\", how=\"inner\")\n",
    "    .with_columns(\n",
    "        context_start=(\n",
    "            pl.when(pl.col(\"tok_pos\") > context_length).then(pl.col(\"tok_pos\") - context_length).otherwise(0)\n",
    "        )\n",
    "    )\n",
    "    .with_columns(\n",
    "        context=pl.col(\"input_ids\").list.slice(\n",
    "            offset=pl.col(\"context_start\"), length=pl.col(\"tok_pos\") - pl.col(\"context_start\") + 1\n",
    "        )\n",
    "    )\n",
    "    .drop([\"input_ids\"])\n",
    ")\n",
    "\n",
    "# check that last token in context is exactly the token we want to predict\n",
    "assert in_vocab_df.with_columns(pl.col(\"context\").list.get(-1) == pl.col(\"new_token_id\"))[\"context\"].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vocab_df = (\n",
    "    out_vocab_sample.join(data.select([\"uid\", \"input_ids\"]), on=\"uid\", how=\"left\")\n",
    "    .with_columns(\n",
    "        context_start=(\n",
    "            pl.when(pl.col(\"tok_pos_b\") > context_length).then(pl.col(\"tok_pos_a\") - context_length + 1).otherwise(0)\n",
    "        )\n",
    "    )\n",
    "    .with_columns(\n",
    "        context=pl.col(\"input_ids\").list.slice(\n",
    "            offset=pl.col(\"context_start\"), length=pl.col(\"tok_pos_a\") - pl.col(\"context_start\") + 2\n",
    "        )\n",
    "    )\n",
    "    .drop([\"input_ids\"])\n",
    ")\n",
    "\n",
    "# Check that penultimate token in context is exactly the first token we want to predict\n",
    "assert out_vocab_df.with_columns(pl.col(\"context\").list.get(-2) == pl.col(\"tok_a\"))[\"context\"].all()\n",
    "\n",
    "# Check that last token in context is exactly the second token we want to predict\n",
    "assert out_vocab_df.with_columns(pl.col(\"context\").list.get(-1) == pl.col(\"tok_b\"))[\"context\"].all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab_df = in_vocab_df.with_columns(context_len=pl.col(\"context\").list.len()).select(\n",
    "    [\"new_token_id\", \"uid\", \"seq_len\", \"tok_pos\", \"context_start\", \"context_len\", \"context\"]\n",
    ")\n",
    "\n",
    "out_vocab_df = out_vocab_df.with_columns(context_len=pl.col(\"context\").list.len()).select(\n",
    "    [\n",
    "        \"new_token_id\",\n",
    "        \"tok_a\",\n",
    "        \"tok_b\",\n",
    "        \"uid\",\n",
    "        \"seq_len\",\n",
    "        \"tok_pos_a\",\n",
    "        \"tok_pos_b\",\n",
    "        \"context_start\",\n",
    "        \"context_len\",\n",
    "        \"context\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab_df.write_parquet(out_path / \"in_vocab.parquet\")\n",
    "out_vocab_df.write_parquet(out_path / \"out_vocab.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in_vocab_df = pl.read_parquet(out_path / \"in_vocab.parquet\")\n",
    "# out_vocab_df = pl.read_parquet(out_path / \"out_vocab.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_context = pl.concat(\n",
    "    [\n",
    "        in_vocab_df.rename({\"context\": \"input_ids\"}).select([\"new_token_id\", \"uid\", \"input_ids\"]), \n",
    "        out_vocab_df.rename({\"context\": \"input_ids\"}).select([\"new_token_id\", \"uid\", \"input_ids\"]),\n",
    "    ]\n",
    ")\n",
    "all_context = all_context.sort(pl.col(\"input_ids\").list.len(), descending=True)\n",
    "\n",
    "ds = Dataset.from_polars(all_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2ed61b382b4358a920f7c615ed71af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/988407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.save_to_disk(out_path / \"contexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15443.859375"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds) / 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: you want at least len_context == 3 because when you compute surprisal you will have 2 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (988_407, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>new_token_id</th><th>uid</th><th>input_ids</th></tr><tr><td>i32</td><td>u32</td><td>list[i32]</td></tr></thead><tbody><tr><td>27619</td><td>4</td><td>[14, 362, … 27619]</td></tr><tr><td>30899</td><td>10</td><td>[19187, 3933, … 30899]</td></tr><tr><td>30025</td><td>25</td><td>[289, 525, … 30025]</td></tr><tr><td>29766</td><td>33</td><td>[14, 199, … 29766]</td></tr><tr><td>29168</td><td>36</td><td>[12312, 13701, … 29168]</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>31905</td><td>501040</td><td>[31905]</td></tr><tr><td>28618</td><td>501066</td><td>[28618]</td></tr><tr><td>28597</td><td>501514</td><td>[28597]</td></tr><tr><td>29742</td><td>502408</td><td>[29742]</td></tr><tr><td>28853</td><td>502412</td><td>[28853]</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (988_407, 3)\n",
       "┌──────────────┬────────┬─────────────────────────┐\n",
       "│ new_token_id ┆ uid    ┆ input_ids               │\n",
       "│ ---          ┆ ---    ┆ ---                     │\n",
       "│ i32          ┆ u32    ┆ list[i32]               │\n",
       "╞══════════════╪════════╪═════════════════════════╡\n",
       "│ 27619        ┆ 4      ┆ [14, 362, … 27619]      │\n",
       "│ 30899        ┆ 10     ┆ [19187, 3933, … 30899]  │\n",
       "│ 30025        ┆ 25     ┆ [289, 525, … 30025]     │\n",
       "│ 29766        ┆ 33     ┆ [14, 199, … 29766]      │\n",
       "│ 29168        ┆ 36     ┆ [12312, 13701, … 29168] │\n",
       "│ …            ┆ …      ┆ …                       │\n",
       "│ 31905        ┆ 501040 ┆ [31905]                 │\n",
       "│ 28618        ┆ 501066 ┆ [28618]                 │\n",
       "│ 28597        ┆ 501514 ┆ [28597]                 │\n",
       "│ 29742        ┆ 502408 ┆ [29742]                 │\n",
       "│ 28853        ┆ 502412 ┆ [28853]                 │\n",
       "└──────────────┴────────┴─────────────────────────┘"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_context = pl.concat(\n",
    "    [\n",
    "        in_vocab_df.rename({\"context\": \"input_ids\"}),\n",
    "        out_vocab_df.rename({\"context\": \"input_ids\"}),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
