{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import causalpy as cp\n",
    "import plotnine as pn\n",
    "import polars as pl\n",
    "import srsly\n",
    "import statsmodels.formula.api as smf\n",
    "import torch\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = Path(\"/home/pl487/rdd/outputs/model_eval/smol_llama-81M-tied_bpe32000minipile_2024-09-30T19-42-18_last_2024-10-08T17-49-06\")\n",
    "df = pl.read_parquet(run_path / \"eval_last.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pl.from_arrow(load_from_disk(\"data/minipile-eval-bpe32000minipile/eval_samples/\").data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hf_from_pl(checkpoint_path: str | Path) -> PreTrainedModel:\n",
    "    checkpoint = torch.load(str(checkpoint_path), weights_only=False)\n",
    "    state_dict = {\n",
    "        k.removeprefix(\"model.\").removeprefix(\"_orig_mod.\"): v\n",
    "        for k, v in checkpoint[\"state_dict\"].items()\n",
    "        if k.startswith(\"model.\")\n",
    "    }\n",
    "    config = checkpoint[\"hyper_parameters\"].get(\"config\")\n",
    "\n",
    "    # HACK: temporary -- since first run for gpt2 was without this info\n",
    "\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_hf_from_pl(\"outputs/model_train_pl/smol_llama-81M-tied_bpe32000minipile_2024-09-30T19-42-18/.checkpoints/last.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = srsly.read_yaml(\"outputs/model_train_pl/smol_llama-81M-tied_bpe32000minipile_2024-09-30T19-42-18/hparams.yaml\")\n",
    "tok = AutoTokenizer.from_pretrained(hparams[\"tok_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(eval_df[0][\"input_ids\"], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.forward(input_ids=t[:, :-1]).logits\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logits.softmax(-1)\n",
    "logprobs = logits.log_softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = t[..., 1:]\n",
    "token_prob = probs.take_along_dim(dim=-1, indices=labels[..., None]).squeeze(-1)\n",
    "token_logprobs = logprobs.take_along_dim(dim=-1, indices=labels[..., None]).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(token_logprobs, token_prob.log(), atol=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = torch.nn.functional.cross_entropy(logits.permute(0, 2, 1), labels, reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(ce.neg(), token_logprobs, atol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def flatten(x: list[list]) -> list:\n",
    "#     return [i for j in x for i in j]\n",
    "\n",
    "\n",
    "# def ld_to_dl(ld: list[dict]) -> dict[str, list]:\n",
    "#     return {k: [dic[k] for dic in ld] for k in ld[0]}\n",
    "\n",
    "\n",
    "# fl = srsly.read_jsonl(\n",
    "#     \"/home/pl487/rdd/outputs/model_eval/pythia-9M-bpe32000_checkpoint-50000_2024-09-17T17-15-44/pythia-9M-bpe32000_checkpoint-50000.jsonl\"\n",
    "# )\n",
    "# df = pl.DataFrame({k: flatten(v) for k, v in ld_to_dl(line).items()} for line in fl)  # type: ignore\n",
    "# df = df.explode(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_tok_path = Path(\"/home/pl487/rdd/outputs/tok_train/bpe_minipile_2024-09-22T17-58-54\")\n",
    "tok = pl.DataFrame(srsly.read_jsonl(Path(raw_tok_path) / \"implemented_merges.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_type = \"bpe\"\n",
    "vocab_size = 32_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-8\n",
    "df = (\n",
    "    df.with_columns(is_out_vocab=pl.col(\"new_token_id\") >= vocab_size).with_columns(\n",
    "        log_prob_true=(\n",
    "            # For token out-of-vocab...\n",
    "            pl.when(pl.col(\"is_out_vocab\"))\n",
    "            # ...keep probs of both tokens creating the merge...\n",
    "            .then(pl.col(\"prob_true\"))\n",
    "            # ...and for those in-vocab only keep the prob of the token itself\n",
    "            .otherwise(pl.col(\"prob_true\").list.slice(-1, 1))\n",
    "            # Compute the log-prob\n",
    "            .list.eval((pl.element() + EPS).log())\n",
    "            # Sum it to get the log-prob of the merge (for in-vocab is simply log-prob of token)\n",
    "            .list.sum()\n",
    "        ),\n",
    "        log_prob_true_and_prefix=(\n",
    "            # For token out-of-vocab...\n",
    "            pl.when(pl.col(\"is_out_vocab\"))\n",
    "            # ...keep probs of both tokens creating the merge...\n",
    "            .then(pl.col(\"prob_true_and_prefix\"))\n",
    "            # ...and for those in-vocab only keep the prob of the token itself\n",
    "            .otherwise(pl.col(\"prob_true_and_prefix\").list.slice(-1, 1))\n",
    "            # Compute the log-prob\n",
    "            .list.eval((pl.element() + EPS).log())\n",
    "            # Sum it to get the log-prob of the merge (for in-vocab is simply log-prob of token)\n",
    "            .list.sum()\n",
    "        ),\n",
    "    )\n",
    "    # .with_columns(pl.col(\"tok_prob_true\").list.len())[\"tok_prob_true\"].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pn.ggplot(df, pn.aes(\"log_prob_true\", fill=\"is_out_vocab\")) + pn.geom_histogram(colour=\"black\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average log-prob per token across contexts\n",
    "avg_df = df.group_by([\"new_token_id\", \"is_out_vocab\"]).agg(\n",
    "    pl.col(\"log_prob_true\").mean(), pl.col(\"log_prob_true_and_prefix\").mean()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = avg_df.join(tok.select([\"new_token_id\", \"count\"]), on=\"new_token_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, col in enumerate(df.columns):\n",
    "#     if df.dtypes[idx] not in (pl.Boolean, pl.List):\n",
    "#         print(col, df[col].is_infinite().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for regression making the scale more compatible\n",
    "avg_df = avg_df.with_columns(pl.col(\"new_token_id\") / 1_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = avg_df.with_columns(\n",
    "    zscore=(pl.col(\"log_prob_true\") - pl.col(\"log_prob_true\").mean()) / pl.col(\"log_prob_true\").std()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df.filter((pl.col(\"new_token_id\") < 32. + .5) & (pl.col(\"new_token_id\") > 32. - .5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = .1\n",
    "regdata = avg_df.filter((pl.col(\"new_token_id\") < 32 + win) & (pl.col(\"new_token_id\") > 32 - win))\n",
    "\n",
    "# Fit model\n",
    "rdd = smf.ols(\n",
    "    \"zscore ~ new_token_id + is_out_vocab + new_token_id:is_out_vocab\", \n",
    "    regdata.to_pandas()\n",
    ").fit(cov_type=\"HC3\")\n",
    "# rdd = (\n",
    "#     smf.ols(\n",
    "#         \"log_prob_true ~ count + is_out_vocab + count:is_out_vocab\", \n",
    "#         avg_df.to_pandas()\n",
    "#     )\n",
    "#     .fit(cov_type=\"HC3\")\n",
    "# )\n",
    "\n",
    "# Compute discontinuity at threasold\n",
    "# discontinuity_at_threshold = rdd.predict({\"new_token_id\": [31.999, 32.0], \"is_out_vocab\": [False, True]}).to_dict()\n",
    "# discontinuity_at_threshold = discontinuity_at_threshold[1] - discontinuity_at_threshold[0]\n",
    "# print(discontinuity_at_threshold)\n",
    "\n",
    "rdd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    pn.ggplot(regdata, pn.aes(x=\"new_token_id\", y=\"zscore\"))\n",
    "    + pn.geom_point(alpha=0.15)\n",
    "    + pn.geom_line(pn.aes(y=rdd.fittedvalues, color=\"is_out_vocab\"), size=2)\n",
    "    # + pn.coord_cartesian(ylim=(-8, -5))\n",
    "    # + pn.geom_vline(xintercept=vocab_size / 1000, linetype=\"dashed\", color=\"black\")\n",
    "    # + pn.scale_x_reverse()\n",
    "    # + pn.labs(x=\"\", y=\"\", colour=\"\", title=f\"Discontinuity at threshold: {discontinuity_at_threshold:.2f}\")\n",
    "    + pn.scale_colour_discrete(guide=None)\n",
    "    + pn.theme_bw()\n",
    "    # pn.scale_y_log10()\n",
    ")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df.group_by(\"is_out_vocab\").agg(pl.col(\"log_prob_true\").mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "rdd = smf.ols(\n",
    "    \"log_prob_true_and_prefix ~ new_token_id + is_out_vocab + new_token_id:is_out_vocab\", avg_df.to_pandas()\n",
    ").fit(cov_type=\"HC3\")\n",
    "\n",
    "# Compute discontinuity at threasold\n",
    "discontinuity_at_threshold = rdd.predict({\"new_token_id\": [31.999, 32.0], \"is_out_vocab\": [False, True]}).to_dict()\n",
    "discontinuity_at_threshold = discontinuity_at_threshold[1] - discontinuity_at_threshold[0]\n",
    "print(discontinuity_at_threshold)\n",
    "\n",
    "rdd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    pn.ggplot(avg_df, pn.aes(x=\"new_token_id\", y=\"log_prob_true_and_prefix\"))\n",
    "    + pn.geom_point(alpha=0.15)\n",
    "    + pn.geom_line(pn.aes(y=rdd.fittedvalues, color=\"is_out_vocab\"), size=2)\n",
    "    # pn.coord_cartesian(ylim=(4, 12)) +\n",
    "    + pn.geom_vline(xintercept=vocab_size / 1000, linetype=\"dashed\", color=\"black\")\n",
    "    + pn.labs(x=\"\", y=\"\", colour=\"\", title=f\"Discontinuity at threshold: {discontinuity_at_threshold:.2f}\")\n",
    "    + pn.scale_colour_discrete(guide=None)\n",
    "    + pn.theme_bw()\n",
    "    # pn.scale_y_log10()\n",
    ")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "result = cp.RegressionDiscontinuity(\n",
    "    data=avg_df.to_pandas().rename(columns={\"is_out_vocab\": \"treated\"}),\n",
    "    formula=\"log_prob_true ~ 1 + new_token_id + treated\",\n",
    "    model=LinearRegression(),\n",
    "    treatment_threshold=vocab_size / 1_000,\n",
    "    running_variable_name=\"new_token_id\",\n",
    ")\n",
    "\n",
    "# fig, ax = result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.print_coefficients()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
