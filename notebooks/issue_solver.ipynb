{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import plotnine as pn\n",
    "import polars as pl\n",
    "import statsmodels.formula.api as smf\n",
    "from datasets import load_from_disk\n",
    "from IPython.display import HTML, display\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(tok: PreTrainedTokenizer, input_ids: list[int], highlight_ids: list[int], highlight_color: str = \"green\") -> None:\n",
    "    print(f\"Checking tokens ids: {highlight_ids}\")\n",
    "    print(f\"Checking tokens: {tok.convert_ids_to_tokens(highlight_ids)}\")\n",
    "    \n",
    "    # Convert token IDs to tokens\n",
    "    tokens = tok.convert_ids_to_tokens(input_ids, skip_special_tokens=False)\n",
    "\n",
    "    # Highlight tokens that are in highlight_ids\n",
    "    highlighted_tokens = [\n",
    "        f\"<span style='background-color:{highlight_color}'>{tok}</span>\" if input_ids[i] in highlight_ids else tok\n",
    "        for i, tok in enumerate(tokens)\n",
    "    ]\n",
    "\n",
    "    # Convert tokens back to a single string\n",
    "    decoded_string = tok.convert_tokens_to_string(highlighted_tokens)\n",
    "\n",
    "    # Display the result in Jupyter notebook\n",
    "    display(HTML(decoded_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_type = \"bpe\"\n",
    "vocab_size = 32_000\n",
    "dataset = \"minipile\"\n",
    "tok_path = Path(f\"./outputs/tokenizers/{tok_type}{vocab_size}{dataset}\")\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(tok_path)\n",
    "eval_df = (\n",
    "    pl.from_arrow(load_from_disk(\"data/minipile-eval-bpe32000minipile/eval_samples/\").data.table)\n",
    "    .with_columns(pl.col(\"uid\").cast(pl.Int64), pl.col(\"new_token_id\").cast(pl.Int64))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vocab_path = Path(\"/home/pl487/rdd/data/minipile-eval-bpe32000minipile/out_vocab_samples.parquet\")\n",
    "out_df = pl.read_parquet(out_vocab_path).with_columns(pl.col(\"uid\").cast(pl.Int64), pl.col(\"new_token_id\").cast(pl.Int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/home/pl487/rdd/outputs/model_eval/\")\n",
    "exp_name = \"smol_llama-81M-tied_bpe32000minipile_2024-09-30T19-42-18_last_2024-10-08T17-49-06\"\n",
    "path = base_path / exp_name / \"eval_last.parquet\"\n",
    "df = (\n",
    "    pl.read_parquet(path)\n",
    "    # .with_row_index(name=\"doc_idx\")\n",
    "    # .with_columns(pl.col(\"doc_idx\").cast(pl.UInt64))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_pos = (\n",
    "#     df\n",
    "#     # .drop(\"doc_idx\")\n",
    "#     .with_columns(tok_pos=pl.int_ranges(pl.col(\"token_logprob\").list.len()))\n",
    "#     .explode([\"token_logprob\", \"tok_pos\"])\n",
    "#     .group_by(\"tok_pos\")\n",
    "#     .agg(\n",
    "#         mean=pl.col(\"token_logprob\").mean(),\n",
    "#         std=pl.col(\"token_logprob\").std(),\n",
    "#     )\n",
    "#     .sort([\"mean\", \"std\"], descending=False)\n",
    "# )\n",
    "# avg_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df\n",
    "    .with_columns(in_vocab=pl.col(\"new_token_id\") < 32000)\n",
    "    .with_columns(\n",
    "        token_logps=(\n",
    "            pl.when(pl.col(\"in_vocab\"))\n",
    "            .then(pl.col(\"token_logprob\").list.tail(1))\n",
    "            .otherwise(pl.col(\"token_logprob\").list.tail(2))\n",
    "        )\n",
    "    )\n",
    "    .with_columns(logp=pl.col(\"token_logps\").list.sum())\n",
    "    .sort(\"logp\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.join(\n",
    "        (\n",
    "            out_df\n",
    "            .select([\"uid\", \"new_token_id\", \"tok_a\", \"tok_b\"])\n",
    "            .unique()\n",
    "            .with_columns(pl.col(\"uid\").cast(pl.Int64), pl.col(\"new_token_id\").cast(pl.Int64))\n",
    "        ),\n",
    "        on=[\"uid\", \"new_token_id\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .with_columns(toks=pl.when(pl.col(\"tok_a\").is_null()).then(pl.concat_list(\"new_token_id\")).otherwise(pl.concat_list([\"tok_a\", \"tok_b\"])))\n",
    "    .drop([\"tok_a\", \"tok_b\"])\n",
    "    .with_columns(in_vocab=pl.col(\"toks\").list.len() == 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pn.ggplot(df.with_row_index(), pn.aes(\"index\", \"logp\")) +\n",
    "    pn.geom_line()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = (\n",
    "    df.join(eval_df, on=[\"new_token_id\", \"uid\"])\n",
    "    .select([\"new_token_id\", \"uid\", \"token_logprob\", \"input_ids\"])\n",
    "    .unique()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = df.head(10).join(eval_df, on=[\"new_token_id\", \"uid\"], how=\"inner\")\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "input_ids = dd[idx][\"input_ids\"].to_list()[0]\n",
    "highlight_ids = dd[idx][\"toks\"].to_list()[0]\n",
    "decode_sequence(tok, input_ids, highlight_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 100\n",
    "dd = (\n",
    "    df.filter(\n",
    "        # (pl.col(\"logp\") > -3.5)\n",
    "        # & (pl.col(\"logp\") < -2.5)\n",
    "        (pl.col(\"new_token_id\") < 32000 + window)\n",
    "        & (pl.col(\"new_token_id\") > 32000 - window)\n",
    "    )\n",
    "    .group_by([\"new_token_id\", \"in_vocab\"])\n",
    "    .agg(avg_logp=pl.col(\"logp\").mean())\n",
    "    .to_pandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n",
    "rdd = smf.ols(\"avg_logp ~ new_token_id + in_vocab\", dd).fit(cov_type=\"HC3\")\n",
    "rdd.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (\n",
    "    pn.ggplot(dd, pn.aes(x=\"new_token_id\", y=\"avg_logp\"))\n",
    "    + pn.geom_point(alpha=0.15)\n",
    "    + pn.geom_line(pn.aes(y=rdd.fittedvalues, color=\"in_vocab\"), size=2)\n",
    "    # + pn.coord_cartesian(ylim=(-8, -5))\n",
    "    # + pn.geom_vline(xintercept=vocab_size / 1000, linetype=\"dashed\", color=\"black\")\n",
    "    # + pn.scale_x_reverse()\n",
    "    # + pn.labs(x=\"\", y=\"\", colour=\"\", title=f\"Discontinuity at threshold: {discontinuity_at_threshold:.2f}\")\n",
    "    + pn.scale_colour_discrete(guide=None)\n",
    "    + pn.theme_bw()\n",
    "    # pn.scale_y_log10()\n",
    ")\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win = .1\n",
    "regdata = avg_df.filter((pl.col(\"new_token_id\") < 32 + win) & (pl.col(\"new_token_id\") > 32 - win))\n",
    "\n",
    "# Fit model\n",
    "rdd = smf.ols(\n",
    "    \"zscore ~ new_token_id + is_out_vocab + new_token_id:is_out_vocab\", \n",
    "    regdata.to_pandas()\n",
    ").fit(cov_type=\"HC3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_vocab_path = Path(\"/home/pl487/rdd/data/minipile-eval-bpe32000minipile/in_vocab_samples.parquet\")\n",
    "\n",
    "\n",
    "in_df = pl.read_parquet(in_vocab_path).with_columns(pl.col(\"uid\").cast(pl.Int64), pl.col(\"new_token_id\").cast(pl.Int64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    df.join(\n",
    "        (\n",
    "            out_df\n",
    "            .select([\"uid\", \"new_token_id\", \"tok_a\", \"tok_b\"])\n",
    "            .with_columns(pl.col(\"uid\").cast(pl.Int64), pl.col(\"new_token_id\").cast(pl.Int64))\n",
    "        ),\n",
    "        on=[\"uid\", \"new_token_id\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .with_columns(toks=pl.when(pl.col(\"tok_a\").is_null()).then(pl.concat_list(\"new_token_id\")).otherwise(pl.concat_list([\"tok_a\", \"tok_b\"])))\n",
    "    .drop([\"tok_a\", \"tok_b\"])\n",
    "    .with_columns(in_vocab=pl.col(\"toks\").list.len() == 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    logp=(\n",
    "        pl.when(pl.col(\"in_vocab\"))\n",
    "        .then(pl.col(\"token_logprob\").list.tail(1))\n",
    "        .otherwise(pl.col(\"token_logprob\").list.tail(2))\n",
    "    )\n",
    ").filter(pl.col(\"in_vocab\").not_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
